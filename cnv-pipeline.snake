# -*- coding: utf-8 -*-

import os
import tempfile
import yaml
from scripts.py_helpers import read_sample_table
# Configuration ================================================================


if not config:
  # This should not happen unless the snakefile is invoked directly from cmd-line
  # try to load a baseline config file
  CONFIGFILE = "config.yaml"
  configfile: CONFIGFILE
  removetempconfig = False
else:
  # Save config to tempfile & use that instead, this ensures the combined default + user configs are used
  # It also archives all options passed by command line and allows them all to be displayed in report
  f, CONFIGFILE = tempfile.mkstemp(suffix = '.yaml', text=True)
  os.close(f)
  removetempconfig = True
  with open(CONFIGFILE, 'w') as yamlout:
    yaml.dump(config, yamlout)


SAMPLETABLE = config['sample_table'] if 'sample_table' in config else 'sample_table.txt' # Defined by wrapper
SNAKEDIR = config['snakedir'] if 'snakedir' in config else os.getcwd() #Defined by wrapper 
BASEPATH = config['basedir'] if 'basedir' in config else os.getcwd() #Defined by wrapper
DATAPATH = config['data_path']
LOGPATH = config['log_path']
TARGET = config['target'] if 'target' in config else 'report' #Defined by wrapper
IDAT_INPUT = config['raw_data_folder']

wildcard_constraints:
  chr=config['wildcard_constraints']['chr'],
  filter=config['wildcard_constraints']['filter'],
  #sample_id=config['wildcard_constraints']['sample_id'],
  #sentrix_name=config['wildcard_constraints']['sentrix_name'],
  #sentrix_pos=config['wildcard_constraints']['sentrix_pos'],

#Never submit these to cluster
localrules:
  relink_gencall,
  all

sample_data = read_sample_table(SAMPLETABLE)
#print(sample_data)


# Rules ========================================================================

def get_target_files():
  #('report', 'processed-calls', 'PennCNV', 'CBS', 'GADA', 'filtered-data', 'unfiltered-data'),
  filter = config['settings']['filter']['use-filterset']
  # Report
  if TARGET == 'report':
    return [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.CNV-report.html") for
     _, sample_id, _, _ in sample_data.values()]
  # Target Processed-calls
  if TARGET == 'processed-calls':
    return [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.combined-cnv-calls.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()]
  # Target PennCNV
  if TARGET == 'PennCNV':
    return [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-autosomes.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()] +\
      [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-chrx.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()] +\
    [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-chry.{filter}.tsv") for
      _, sample_id, sex, _ in sample_data.values() if sex.lower()[0] == 'm']
  # Target CBS
  if TARGET == 'CBS':
    return [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.CBS.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()]
  # Target CBS
  if TARGET == 'GADA':
    return [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.GADA.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()]
  #Target: filtered-data
  if TARGET == 'filtered-data':
    return  [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.filtered-data.{filter}.tsv") for
      _, sample_id, _, _ in sample_data.values()] #+\
      # TODO: add filtered vcf file!
      # [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.filtered.{filter}.vcf") for
      # _, sample_id, _, _ in sample_data.values()]
  #Target: unfiltered-data
  if TARGET == 'unfiltered-data':
    return  [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.processed-data.tsv") for
      _, sample_id, _, _ in sample_data.values()] +\
      [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.unprocessed.vcf") for
      _, sample_id, _, _ in sample_data.values()]


rule all:
  input:
    get_target_files()
  run:
    if removetempconfig:
      os.remove(CONFIGFILE)
    

# MAYBE: make the gtc files intermediate? they are only needed once really
# -> would allow an easier structure for output data
# Optional(/Alternative?):
# - make temp folder that link to specific idat files only so that gencall is only run a one a sample at a time
rule run_gencall:
  input:
    bpm=config['static_data']['bpm_manifest_file'],
    egt=config['static_data']['egt_cluster_file'],
    idat_path = os.path.join(IDAT_INPUT, "{sentrix_name}")
  output:
    os.path.join(BASEPATH, DATAPATH, "gtc", "{sentrix_name}", "_done")
  threads: config['tools']['GenCall']['threads']
  resources:
    time=config['tools']['GenCall']['runtime'],
    mem_mb=config['tools']['GenCall']['memory'],
    partition='medium'
  params:
    #TODO: check which options make sense here
    options = config['tools']['GenCall']['cmd-line-params'],
    outpath = os.path.join(BASEPATH, DATAPATH, "gtc", "{sentrix_name}")
  log:
    err=os.path.join(BASEPATH, LOGPATH, "GenCall", "{sentrix_name}", "error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "GenCall", "{sentrix_name}", "out.log")
  shell:
    #TODO: check how imporant definition of the ICU version & LANG is here
    # CLR_ICU_VERSION_OVERRIDE="70.1" / $(uconv -V | sed 's/.* //g')
    'LANG="en_US.UTF-8" iaap-cli gencall {input.bpm} {input.egt} {params.outpath} --idat-folder {input.idat_path} --output-gtc {params.options} -t {threads} > {log.out} 2> {log.err} && [ $(ls {params.outpath}/*.gtc -l | wc -l) -ge 1 ] && touch {output} || exit 1'


# The iaap-cli will *always* generate filenames bderived from the sentrix name & pos
def get_chip(wildcards, outtype = 'dir_path'):
  """Get the chip name from a sample_id
  Values for outtype: 'dirpath' | 'file'"""
  chip_name, chip_pos = [n for _,(n, p, i, _, _) in sample_data.items() if i == wildcards.sample_id][0]
  if outtype == 'dir_path':
    return os.path.join(BASEPATH, 'data', 'gtc', chip_name)
  elif outtype == 'file':
    return os.path.join(chip_name, chip_name + '_', + chip_pos + '.gtc')


rule relink_gencall:
  input:
    lambda wildcards: os.path.join(get_chip(wildcards), '_done')
  output:
    os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.gencall.gtc")
  params:
    #TODO test relative link
    gtc_link_path = lambda wildcards: os.path.join('../gtc/data', get_chip(wildcards, outtype='file'))
  shell:
    "ln -s {params.gtc_link_path} {output}"
  

rule run_gtc2vcf_tsv:
  input:
    bpm=config['static_data']['bpm_manifest_file'],
    egt=config['static_data']['egt_cluster_file'],
    genome=config['static_data']['genome_fasta_file'],
    gtc = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.gencall.gtc"),
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.processed-data.tsv"),
  threads: 1
  resources:
    time=config['tools']['gtc2vcf']['runtime'],
    mem_mb=config['tools']['gtc2vcf']['memory'],
    partition='medium'
  params:
    options = config['tools']['gtc2vcf']['cmd-line-params'],
    csv='--csv {}'.format(config['static_data']['csv_manifest_file']) if config['static_data']['csv_manifest_file'] else '',
  log:
    err=os.path.join(BASEPATH, LOGPATH, "gtc2vcf", "{sample_id}", "tsv.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "gtc2vcf", "{sample_id}", "tsv.out.log")
  shell:
    'bcftools plugin gtc2vcf {params.options} --no-version -O t --bpm {input.bpm} {params.csv} --egt {input.egt} --fasta-ref {input.genome} -o {output.tsv} {input.gtc} > {log.out} 2> {log.err}'

rule run_gtc2vcf_vcf:
  input:
    bpm=config['static_data']['bpm_manifest_file'],
    egt=config['static_data']['egt_cluster_file'],
    genome=config['static_data']['genome_fasta_file'],
    gtc = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.gencall.gtc")
  output:
    vcf = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.unprocessed.vcf"),
    metatxt = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.stats.txt"),
  threads: 1
  resources:
    time=config['tools']['gtc2vcf']['runtime'],
    mem_mb=config['tools']['gtc2vcf']['memory'],
    partition='medium',
  params:
    options = config['tools']['gtc2vcf']['cmd-line-params'],
    csv='--csv {}'.format(config['static_data']['csv_manifest_file']) if config['static_data']['csv_manifest_file'] else '',
  log:
    err=os.path.join(BASEPATH, LOGPATH, "gtc2vcf", "{sample_id}", "vcf.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "gtc2vcf", "{sample_id}", "vcf.out.log"),
  shell:
    'bcftools plugin gtc2vcf {params.options} --no-version -O v --bpm {input.bpm} {params.csv} --egt {input.egt} --fasta-ref {input.genome} --extra {output.metatxt} -o {output.vcf} {input.gtc} > {log.out} 2> {log.err}'
 
rule filter_tsv:
  input:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.processed-data.tsv")
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.filtered-data.{filter}.tsv")
  threads: 1
  log:
    err=os.path.join(BASEPATH, LOGPATH, "filter_tsv", "{sample_id}", "{filter}.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "filter_tsv", "{sample_id}", "{filter}.out.log")
  shell:
    'Rscript {SNAKEDIR}/scripts/filter_data.R -f {wildcards.filter} {input.tsv} {output.tsv} > {log.out} 2> {log.err}'
    
rule make_PennCNV_sexfile:
  output:
    filename=temp(os.path.join(BASEPATH, "penncnv-sexfile.txt"))
  # a 2-column file containing filename and sex (male/female) for
  # sex chromosome calling with -chrx argument. The first
  # tab-delimited column should be the input signal file name, while
  # the second tab-delimited column should be male or female.
  # Alternatively, abbreviations including m (male), f (female), 1
  # (male) or 2 (female) are also fine.
  params:
    filter = config['settings']['filter']['use-filterset']
  run:
    with open(output.filename, 'w') as f:
      for _, sample_id, sex, _ in sample_data.values():
        inputfile = os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.filtered-data.{params.filter}.tsv")
        #ensure its consistently 'm'/'f'
        sex = sex.lower()[0]
        f.write(f"{inputfile}\t{sex}\n")

#TODO: set PennCNV ressources &/ set defaults
rule run_PennCNV_auto:
  input:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.filtered-data.{filter}.tsv"),
    pfb = config['static_data']['pfb_file'],
    gcmodel = config['static_data']['GCmodel_file']
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.penncnv-autosomes.{filter}.tsv")
  threads: 1
  # resources:
  #   time=...
  #   memory=...
  #   partition=...
  log:
    err=os.path.join(BASEPATH, LOGPATH, "PennCNV", "{sample_id}", "auto.{filter}.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "PennCNV", "{sample_id}", "auto.{filter}.out.log")
  shell:
    'PennCNV_detect -test -loh -confidence -hmm {SNAKEDIR}/PennCNV_overrides/hhall_loh.hmm -pfb {input.pfb} -gcmodel {input.gcmodel} {input.tsv} -out {output.tsv} > {log.out} 2> {log.err}'


rule run_PennCNV_sex:
  input:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.filtered-data.{filter}.tsv"),
    sexfile = ancient(os.path.join(BASEPATH, "penncnv-sexfile.txt")),
    pfb = config['static_data']['pfb_file'],
    gcmodel = config['static_data']['GCmodel_file']
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.penncnv-{chr}.{filter}.tsv")
  threads: 1
  # resources:
  #   time=...
  #   memory=...
  #   partition=...
  log:
    err=os.path.join(BASEPATH, LOGPATH, "PennCNV", "{sample_id}", "{chr}.{filter}.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "PennCNV", "{sample_id}", "{chr}.{filter}.out.log")
  shell:
    'PennCNV_detect -test -loh -confidence -hmm {SNAKEDIR}/PennCNV_overrides/hhall_loh.hmm -pfb {input.pfb} -gcmodel {input.gcmodel} -{wildcards.chr} -sex {input.sexfile} {input.tsv} -out {output.tsv} > {log.out} 2> {log.err}'

#? maybe ??
# make a rule to merge PennCNV files?
# -> that rule would also need to check sex though

rule run_CBS:
  input:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.filtered-data.{filter}.tsv")
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.CBS.{filter}.tsv")
  threads: 1
  params:
    SDundo = config['settings']['CBS']['SDundo']
  log:
    err=os.path.join(BASEPATH, LOGPATH, "CBS", "{sample_id}", "{filter}.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "CBS", "{sample_id}", "{filter}.out.log")
  shell:
    "Rscript {SNAKEDIR}/scripts/run_CBS_DNAcopy.R -s {params.SDundo} {input.tsv} {output.tsv} > {log.out} 2> {log.err}"

rule run_GADA:
  input:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.filtered-data.{filter}.tsv")
  output:
    tsv = os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.GADA.{filter}.tsv")
  threads: 1
  params:
    alpha = config['settings']['GADA']['aAlpha'],
    gadaT = config['settings']['GADA']['gada.T'],
    madT = config['settings']['GADA']['mad.T'],
    minLen = config['settings']['GADA']['MinSegLen']
  log:
    err=os.path.join(BASEPATH, LOGPATH, "GADA", "{sample_id}", "{filter}.err.log"),
    out=os.path.join(BASEPATH, LOGPATH, "GADA", "{sample_id}", "{filter}.out.log")
  shell:
    "Rscript {SNAKEDIR}/scripts/run_GADA.R -a {params.alpha} -g {params.gadaT} -m {params.madT} -l {params.minLen} {input.tsv} {output.tsv} > {log.out} 2> {log.err}"

# rule process_CNV_calls:
#   -> currently done in report; move out ?

def get_ref_id(wildcards, get_sex=False):
  sex, ref_name = [(s, r) for name,(_, _, i, s, r) in sample_data.items() if i == wildcards.sample_id][0]
  sample_id = wildcards.sample_id
  if ref_name and ref_name in sample_data:
    _, ref_id, ref_sex, _ = sample_data[ref_name]
  elif ref_name:
    # listed reference does not exist in sampletable
    # TODO make a nicer exception class
    raise Exception(f"Listed reference sample can not be found in sample-table: '{ref_name}'")
  else:
    ref_id = False
    ref_sex = False

  if get_sex:
    return sample_id, ref_id, sex, ref_sex
  else:
    return sample_id, ref_id

def get_preprocess_input(wildcards):
  sample_id, ref_id, sex, ref_sex = get_ref_id(wildcards, True)
  filter = config['settings']['filter']['use-filterset']
  tools = config['settings']['CNV.calling.tools']
  files = []
  files += [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-autosomes.{filter}.tsv"),
            os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-chrx.{filter}.tsv")] if 'PennCNV' in tools else []
  files += [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.penncnv-chry.{filter}.tsv")] if 'PennCNV' in tools and sex[0].lower() == 'm' else []
  files += [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.CBS.{filter}.tsv")] if 'CBS' in tools else []
  files += [os.path.join(BASEPATH, DATAPATH, f"{sample_id}", f"{sample_id}.GADA.{filter}.tsv")] if 'GADA' in tools else []

  files += [os.path.join(BASEPATH, DATAPATH, f"{ref_id}", f"{ref_id}.combined-cnv-calls.{filter}.tsv")] if ref_id else []

  return files

rule process_CNV_calls:
  input:
    get_preprocess_input
  output:
    os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.combined-cnv-calls.{filter}.tsv")
  resources:
    time=config['tools']['CNV.process']['runtime'],
    mem_mb=config['tools']['CNV.process']['memory'],
    partition='medium'
  params:
    gada = '-g' if 'GADA' in config['settings']['CNV.calling.tools'] else '',
    penncnv = '-p' if 'PennCNV' in config['settings']['CNV.calling.tools'] else '',
    cbs = '-c' if 'CBS' in config['settings']['CNV.calling.tools'] else ''
  log:
    err=os.path.join(BASEPATH, LOGPATH, "CNV_process", "{sample_id}", "{filter}.error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "CNV_process", "{sample_id}", "{filter}.out.log")
  shell:
    "Rscript {SNAKEDIR}/scripts/process_CNV_calls.R {params.penncnv} {params.gada} {params.cbs} {BASEPATH}/data {wildcards.sample_id} {CONFIGFILE} {SAMPLETABLE} > {log.out} 2> {log.err}"


def get_report_sample_input(wildcards):
  sample_id, ref_id = get_ref_id(wildcards)
  return expand(
          [os.path.join(BASEPATH, DATAPATH, "{ids}", "{ids}.combined-cnv-calls.{filter}.tsv"),
           os.path.join(BASEPATH, DATAPATH, "{ids}", "{ids}.stats.txt"),
           os.path.join(BASEPATH, DATAPATH, "{ids}", "{ids}.processed-data.tsv"),],
           ids = (sample_id, ref_id) if ref_id else (sample_id,),
           filter = config['settings']['filter']['use-filterset']
          )

rule knit_report:
  input:
    get_report_sample_input
  output:
    html=os.path.join(BASEPATH, DATAPATH, "{sample_id}", "{sample_id}.CNV-report.html"),
    plots=directory(os.path.join(BASEPATH, DATAPATH, "{sample_id}", "report_images"))
  resources:
    time=config['tools']['knitr']['runtime'],
    mem_mb=config['tools']['knitr']['memory'],
    partition='medium'
  log:
    err=os.path.join(BASEPATH, LOGPATH, "report", "{sample_id}", "error.log"),
    out=os.path.join(BASEPATH, LOGPATH, "report", "{sample_id}", "out.log")
  shell:
    "Rscript {SNAKEDIR}/scripts/knit_report.R {wildcards.sample_id} {CONFIGFILE} > {log.out} 2> {log.err}"
